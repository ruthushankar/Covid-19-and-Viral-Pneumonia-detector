# -*- coding: utf-8 -*-
"""Viral_pneumonia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1galUU5AtilU4gWqpFtmA6TH2fq0Mg3jg

# Detecting Viral Pneumonia with Chest X Ray using PyTorch
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
#Importing all necesssary libraries
import os
import shutil
import random
import torch
import torchvision
import numpy as np
from PIL import Image
from matplotlib import pyplot as plt
torch.manual_seed(0)
print('Using PyTorch version', torch.__version__)

from google.colab import drive
drive.mount('/content/drive')

from PIL import Image
target_dir="/content/drive/My Drive/Radiography Database"

"""# Preparing Training and Test Sets"""

class_names = ['normal', 'viral']
root_dir = 'Radiography Database'
source_dirs = ['NORMAL', 'Viral Pneumonia']

if os.path.isdir(os.path.join(root_dir, source_dirs[1])):
    os.mkdir(os.path.join(root_dir, 'test'))

    for i, d in enumerate(source_dirs):
        os.rename(os.path.join(root_dir, d), os.path.join(root_dir, class_names[i]))

    for c in class_names:
        os.mkdir(os.path.join(root_dir, 'test', c))

    for c in class_names:
        images = [x for x in os.listdir(os.path.join(root_dir, c)) if x.lower().endswith('png')]
        selected_images = random.sample(images, 30)
        for image in selected_images:
            source_path = os.path.join(root_dir, c, image)
            target_path = os.path.join(root_dir, 'test', c, image)
            shutil.move(source_path, target_path)

class ChestXRayDataset(torch.utils.data.Dataset):
    def __init__(self, image_dirs, transform):   # transform used in data augmentation
        def get_images(class_name):
            images = [x for x in os.listdir(image_dirs[class_name]) if x[-3:].lower().endswith('png')]
            print(f'Found {len(images)} {class_name} examples')
            return images
        
        self.images = {}
       # self.class_names = ['normal', 'viral',]
        self.class_names = ['normal', 'viral']   # 2 classes
        
        for class_name in self.class_names:
            self.images[class_name] = get_images(class_name)
            
        self.image_dirs = image_dirs
        self.transform = transform
        
    
    def __len__(self):
        return sum([len(self.images[class_name]) for class_name in self.class_names])
    
    
    def __getitem__(self, index):
        class_name = random.choice(self.class_names)
        index = index % len(self.images[class_name])
        image_name = self.images[class_name][index]
        image_path = os.path.join(self.image_dirs[class_name], image_name)
        image = Image.open(image_path).convert('RGB')
        return self.transform(image), self.class_names.index(class_name)

"""# Image Transformations"""

# 1300 samples of x rays for each.
# # Data augmentation and normalization for training set
# many variations of the original images 

train_transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize(size=(224, 224)), # Resizing the images with/without padding.
    torchvision.transforms.RandomHorizontalFlip(),  # flips image if not aligned properly
    torchvision.transforms.ToTensor(),              #input image  converted to PyTorch tensor.
    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # precomputed mean and std values
])

test_transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize(size=(224, 224)),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

"""# Prepare DataLoader"""

train_dirs = {
 
    'normal': '/content/drive/My Drive/Radiography Database/normal', # locating images on the drive.
    'viral': '/content/drive/My Drive/Radiography Database/viral',
}

train_dataset = ChestXRayDataset(train_dirs, train_transform)

test_dirs = {

    'normal': '/content/drive/My Drive/Radiography Database/test/c',
    'viral': '/content/drive/My Drive/Radiography Database/test/v',
}

test_dataset = ChestXRayDataset(test_dirs, test_transform)

batch_size = 6 #is a hyperparameter that defines the number of samples to work through before updating the internal model parameters.

dl_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # loading training data
dl_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)   # loading test data.

print('Number of training batches', len(dl_train))# 452 training batches
print('Number of test batches', len(dl_test))# 8 testing batches

"""# Data Visualization"""

class_names = train_dataset.class_names

# defining a func to print images for future use.
def show_images(images, labels, preds):
    plt.figure(figsize=(8, 4))
    for i, image in enumerate(images):
        plt.subplot(1, 6, i + 1, xticks=[], yticks=[])  # prints one row with 6 images in it.
        image = image.numpy().transpose((1, 2, 0))
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        image = image * std + mean
        image = np.clip(image, 0., 1.)
        plt.imshow(image)
        col = 'green'             # green if label=label as in the dataset
        if preds[i] != labels[i]:
            col = 'red'           # red is label!=label as in dataset.
            
        plt.xlabel(f'{class_names[int(labels[i].numpy())]}')            # printing x label
        plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=col)  # printing y label
    plt.tight_layout()
    plt.show()

images, labels = next(iter(dl_train)) # training data
show_images(images, labels, labels)

images, labels = next(iter(dl_test))  # testing data
show_images(images, labels, labels)

"""# Creating the Model"""

# # using Transfer learning. Using pre trained model called resnet.
#  These pre-trained models allow others to quickly obtain cutting edge results in computer vision without needing the large amounts of compute power, time,
#  and patience in finding the right training technique to optimize the weights.

resnet18 = torchvision.models.resnet18(pretrained=True)   # loading the model

# print(resnet18)

resnet18.fc = torch.nn.Linear(in_features=512, out_features=2) # output features.
loss_fn = torch.nn.CrossEntropyLoss()                          #cross entropy loss
optimizer = torch.optim.Adam(resnet18.parameters(), lr=3e-5)   #lr taken to be a small value

def show_preds():
    resnet18.eval()                       # evaluating the resnet model
    images, labels = next(iter(dl_test))  # assigns to the test dataset.
    outputs = resnet18(images)            # assigns variable to output images.           
    _, preds = torch.max(outputs, 1)      # each input image is assigned not more than 1 output label
    show_images(images, labels, preds)    # displays/prints outputs.

show_preds()                              #shows predictions.

"""# Training the Model"""

def train(epochs):
    print('Starting training..')
    for e in range(0, epochs):      # epoch is the input param in this func.
        print('='*20)
        print(f'Starting epoch {e + 1}/{epochs}')
        print('='*20)

        train_loss = 0.  # set all losses to 0 at first.( training and validation)
        val_loss = 0.

        resnet18.train() # set model to training phase

        for train_step, (images, labels) in enumerate(dl_train):
            optimizer.zero_grad()
            outputs = resnet18(images)
            loss = loss_fn(outputs, labels) # checks if outputs are matching with labels
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
            if train_step % 20 == 0:
                print('Evaluating at step', train_step)

                accuracy = 0  # setting initial accuracy as 0.

                resnet18.eval() # set model to eval phase

                for val_step, (images, labels) in enumerate(dl_test):
                    outputs = resnet18(images)
                    loss = loss_fn(outputs, labels)  # computing loss
                    val_loss += loss.item()  # computing validation loss

                    _, preds = torch.max(outputs, 1)
                    accuracy += sum((preds == labels).numpy())

                val_loss /= (val_step + 1)
                accuracy = accuracy/len(test_dataset)
                print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')

                show_preds() 

                resnet18.train()

                if accuracy >= 0.95:
                    print('Performance condition satisfied, stopping..')
                    return

        train_loss /= (train_step + 1)

        print(f'Training Loss: {train_loss:.4f}')
    print('Training is complete')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# train(epochs=100)

